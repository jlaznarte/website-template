Logo Springer

Search Options

    Advanced Search
    Search Help

Search Menu
» Sign up / Log in
English

    Deutsch

Academic edition

    Corporate edition

Skip to: Main content Side column

    Home
    Contact Us

Look Inside Get Access
Find out how to access preview-only content
Chapter

Advances in Knowledge Discovery and Data Mining

Volume 8444 of the series Lecture Notes in Computer Science pp 247-258
Extensions to Quantile Regression Forests for Very High-Dimensional Data

    Nguyen Thanh Tung Affiliated with Shenzhen Key Laboratory of High Performance Data Mining. Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences
    , Joshua Zhexue Huang Affiliated with College of Computer Science and Software Engineering, Shenzhen University
    , Imran Khan Affiliated with Shenzhen Key Laboratory of High Performance Data Mining. Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences
    , Mark Junjie Li Affiliated with College of Computer Science and Software Engineering, Shenzhen University
    , Graham Williams Affiliated with Shenzhen Key Laboratory of High Performance Data Mining. Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences

$29.95 / €24.95 / £19.95 *
Buy eBook
Buy this eBook

$89.00 / €67.82 / £56.99*

* Final gross prices may vary according to local VAT.

* Final gross prices may vary according to local VAT.
Get Access
Abstract

This paper describes new extensions to the state-of-the-art regression random forests Quantile Regression Forests (QRF) for applications to high-dimensional data with thousands of features. We propose a new subspace sampling method that randomly samples a subset of features from two separate feature sets, one containing important features and the other one containing less important features. The two feature sets partition the input data based on the importance measures of features. The partition is generated by using feature permutation to produce raw importance feature scores first and then applying p -value assessment to separate important features from the less important ones. The new subspace sampling method enables to generate trees from bagged sample data with smaller regression errors. For point regression, we choose the prediction value of Y from the range between two quantiles Q 0.05 and Q 0.95 instead of the conditional mean used in regression random forests. Our experiment results have shown that random forests with these extensions outperformed regression random forests and quantile regression forests in reduction of root mean square residuals.
Keywords
Regression Random Forests Quantile Regression Forests Data Mining High-dimensional Data
Page %P
Loading...
Close Plain text
Advances in Knowledge Discovery and Data Mining Advances in Knowledge Discovery and Data Mining Look
Inside
Chapter Metrics

Citations
    2 
Downloads
    1K 

Provided by Book metrix
Reference tools

    Export citation
        EndNote (.ENW)
        JabRef (.BIB)
        Mendeley (.BIB)
        Papers (.RIS)
        Zotero (.RIS)
        BibTeX (.BIB)
    Add to Papers

Other actions

    About this Book
    Reprints and Permissions

Share
Share this content on Facebook Share this content on Twitter Share this content on LinkedIn
Supplementary Material (0)
References (11)
References

    1.
    Breiman, L., Friedman, J.H., Olshen, R.A., Stone, C.: Classification and Regression Trees. Wadsworth International, Belmont (1984)
    2.
    Breiman, L.: Bagging Predictors. Machine Learning 24(2), 123–140 (1996) MATH MathSciNet
    3.
    Breiman, L.: Random Forests. Machine Learning 45(1), 5–32 (2001) CrossRef MATH
    4.
    Ho, T.: The random subspace method for constructing decision forests. IEEE Transactions on Pattern Analysis and Machine Intelligence 20(8), 832–844 (1998) CrossRef
    5.
    Kursa, M.B., Rudnicki, W.R.: Feature Selection with the Boruta Package. Journal of Statistical Software 36(11) (2010)
    6.
    Liaw, A., Wiener, M.: randomForest 4.6-7. R package (2012), http://cran.r-project.org
    7.
    Meinshausen, N.: Quantile Random Forests. Journal Machine Learning Research, 983–999 (2006)
    8.
    Meinshausen, N.: quantregForest 0.2-3. R package (2012), http://cran.r-project.org
    9.
    Rosenwald, A., et al.: The use of molecular profiling to predict survival after chemotherapy for diffuse large-b-cell lymphoma. N. Engl. J. Med. 346, 1937–1947 (2002) CrossRef
    10.
    Stoppiglia, H., Dreyfus, G.: Ranking a random feature for variable and feature selection. The Journal of Machine Learning Research 3, 1399–1414 (2003) MATH
    11.
    Tuv, E., Borisov, A., Runger, G., Torkkola, K.: Feature selection with ensembles, artificial variables, and redundancy elimination. The Journal of Machine Learning Research 10, 1341–1366 (2009) MATH MathSciNet

About this Chapter

Title
    Extensions to Quantile Regression Forests for Very High-Dimensional Data
Book Title
    Advances in Knowledge Discovery and Data Mining 
Book Subtitle
    18th Pacific-Asia Conference, PAKDD 2014, Tainan, Taiwan, May 13-16, 2014. Proceedings, Part II
Pages
    pp 247-258
Copyright
    2014
DOI
    10.1007/978-3-319-06605-9_21
Print ISBN
    978-3-319-06604-2
Online ISBN
    978-3-319-06605-9
Series Title
    Lecture Notes in Computer Science 
Series Volume
    8444
Series ISSN
    0302-9743
Publisher
    Springer International Publishing
Copyright Holder
    Springer International Publishing Switzerland
Additional Links

        About this Book

Topics

        Data Mining and Knowledge Discovery
        Artificial Intelligence (incl. Robotics)
        Information Storage and Retrieval

Keywords

        Regression Random Forests
        Quantile Regression Forests
        Data Mining
        High-dimensional Data

Industry Sectors

        Pharma
        Materials & Steel
        Automotive
        Chemical Manufacturing
        Biotechnology
        Electronics
        IT & Software
        Telecommunications
        Consumer Packaged Goods
        Aerospace
        Oil, Gas & Geosciences
        Engineering

Editors

        Vincent S. Tseng tsengsm@mail.ncku.edu.tw (19)
        Tu Bao Ho bao@jaist.ac.jp (20)
        Zhi-Hua Zhou zhouzh@nju.edu.cn (21)
        Arbee L. P. Chen alpchen@cs.nccu.edu.tw (22)
        Hung-Yu Kao hykao@mail.ncku.edu.tw (19)

Editor Affiliations

        19. National Cheng Kung University
        20. Japan Advanced Institute of Science and Technology
        21. Nanjing University
        22. National Chengchi University

Authors

        Nguyen Thanh Tung tungnt@wru.vn (23)
        Joshua Zhexue Huang zx.huang@szu.edu.cn (24)
        Imran Khan imran.khan@siat.ac.cn (23)
        Mark Junjie Li jj.li@szu.edu.cn (24)
        Graham Williams Graham.Williams@togaware.com (23)

Author Affiliations

        23. Shenzhen Key Laboratory of High Performance Data Mining. Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China
        24. College of Computer Science and Software Engineering, Shenzhen University, China

Continue reading...

To view the rest of this content please follow the download PDF link above.
Over 9 million scientific documents at your fingertips
Browse by Discipline

    Architecture & Design
    Astronomy
    Biomedical Sciences
    Business & Management
    Chemistry
    Computer Science
    Earth Sciences & Geography
    Economics
    Education & Language
    Energy
    Engineering
    Environmental Sciences
    Food Science & Nutrition
    Law
    Life Sciences
    Materials
    Mathematics
    Medicine
    Philosophy
    Physics
    Psychology
    Public Health
    Social Sciences
    Statistics

Our Content

    Journals
    Books
    Book Series
    Protocols
    Reference Works

Other Sites

    Springer.com
    SpringerProtocols
    SpringerMaterials
    AdisInsight

Help & Contacts

    Contact Us
    Impressum

Legal
© Springer International Publishing AG, Part of Springer Science+Business Media Privacy Policy, Disclaimer, General Terms & Conditions
Not logged in Unaffiliated 88.6.101.171
Springer for Research & Development
UA-26408784-1

JavaScript is currently disabled , this site works much better if you enable JavaScript in your browser.

Click to get updates and verify authenticity.
